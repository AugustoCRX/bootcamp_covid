{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "\n",
    "import glob\n",
    "import json\n",
    "\n",
    "from textblob import TextBlob as tb\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json_file(file):\n",
    "    with open(file, \"r\", encoding='utf8') as r:\n",
    "        response = r.read()\n",
    "        response = response.replace('\\n', '')\n",
    "        response = response.replace('}{', '},{')\n",
    "        response = \"[\" + response + \"]\"\n",
    "        return json.loads(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#função de diminuição de dimensionalidade de listas\n",
    "def flatten_list(_2d_list):\n",
    "    flat_list = []\n",
    "    for element in _2d_list:\n",
    "        if type(element) is list:\n",
    "            for item in element:\n",
    "                flat_list.append(item)\n",
    "        else:\n",
    "            flat_list.append(element)\n",
    "    return flat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "caminho_EQ = r\"DATA\"\n",
    "list_EQ = glob.glob(os.path.join(caminho_EQ, '*/*'))\n",
    "\n",
    "# extraindo json e criando lista\n",
    "dict_EQ = list()\n",
    "for i in range(len(list_EQ)):\n",
    "    dict_EQ.append(read_json_file(list_EQ[i]))\n",
    "dict_EQ = flatten_list(dict_EQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extração do \"place_id\" pEQa coleta de dados geográficos\n",
    "data_extraction = []\n",
    "for i in range(len(dict_EQ)):\n",
    "    try:\n",
    "        for j in range(len(dict_EQ[i]['data'])):\n",
    "            place_id = dict_EQ[i]['data'][j]['geo']['place_id']\n",
    "            data_extraction.append(place_id) \n",
    "    except:\n",
    "        continue  \n",
    "data_extraction = list(set(data_extraction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Bot de extração de dados geográficos\n",
    "# # Para execução é necessário tirar os comentários do código\n",
    "# options = webdriver.ChromeOptions() #Execução do webdriver do google\n",
    "# options.add_experimental_option(\"prefs\", {\n",
    "#   \"download.default_directory\": r\"E:\\Blue\\Bootcamp 2\\github\\bootcamp_covid\\data_extraction\\EQUADOR\\GEO\"\n",
    "#   })\n",
    "# browser = webdriver.Chrome(options=options)\n",
    "# browser.get('https://twitter.com/')\n",
    "# time.sleep(2)\n",
    "# # Os elementos serão acessados via xpath, que é o path do HTML do site, buscando botões e caixa de interação\n",
    "# browser.find_element('xpath', '/html/body/div[1]/div/div/div[1]/div/div[1]/div/div/div/div/div/div/div/div[1]/a/div/span/span').click()\n",
    "# time.sleep(2)\n",
    "# # É seguro inserir seus dados, visto que o algoritmo só guardará seus dados na memória do seu computador\n",
    "# login = input('Insira seu nome no twitter (tag)') #Colocar como input\n",
    "# password = input('Insira sua senha') #Colocar como input\n",
    "# browser.find_element('xpath', '//html/body/div[1]/div/div/div[1]/div[2]/div/div/div/div/div/div[2]/div[2]/div/div/div[2]/div[2]/div/div/div/div[5]/label/div/div[2]/div/input').send_keys(login)\n",
    "# time.sleep(2)\n",
    "# browser.find_element('xpath', '/html/body/div[1]/div/div/div[1]/div[2]/div/div/div/div/div/div[2]/div[2]/div/div/div[2]/div[2]/div/div/div/div[6]/div').click()\n",
    "# time.sleep(2)\n",
    "# browser.find_element('xpath', '/html/body/div[1]/div/div/div[1]/div[2]/div/div/div/div/div/div[2]/div[2]/div/div/div[2]/div[2]/div[1]/div/div/div[3]/div/label/div/div[2]/div[1]/input').send_keys(password)\n",
    "# time.sleep(2)\n",
    "# browser.find_element('xpath', '/html/body/div[1]/div/div/div[1]/div[2]/div/div/div/div/div/div[2]/div[2]/div/div/div[2]/div[2]/div[2]/div/div[1]/div/div/div/div/span/span').click()\n",
    "# time.sleep(2)\n",
    "# # Um loop para acessar os dados do \"place_id\" que estão dentro da lista data_extraction\n",
    "# for place_id in data_extraction:  \n",
    "#   browser.get(f'https://api.twitter.com/1.1/geo/id/{place_id}.json')\n",
    "# # A API do twitter restringe o uso da coleta de \"place_id\" em 100 vezes/hora então esse tempo é calculado\n",
    "# # prevendo possíveis \"bugs\" e considerando o tempo limite por hora\n",
    "#   time.sleep(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.listdir('GEO')\n",
    "dict_EQ_GEO = list()\n",
    "for i in path:\n",
    "    with open(f'GEO/{i}', 'r', encoding='utf8') as f:\n",
    "        dict_EQ_GEO.append(json.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A estrutura da lista funciona com o seguinte padrão:\n",
    "# O primeiro objeto (dict_AR[i]) é o tweet de várias pessoas que falaram sobre o assunto covid naquele dia\n",
    "# Dentro do objeto citado anteriormente podemos acessar as seguintes informações:\n",
    "######### data #########\n",
    "# Inclui os dados do tweet em si \n",
    "######### includes #########\n",
    "# Inclui os dados do usuário que tweetou\n",
    "######### meta #########\n",
    "# Inclui informações sobre a pesquisa\n",
    "# Com isso, as informações que serão coletadas serão:\n",
    "# - Texto\n",
    "# - Data\n",
    "# - Quantidade de Retweet\n",
    "# - Quantidade de likes\n",
    "# - Grau inicial de polaridade (Utilizando a biblioteca TextBlob)\n",
    "# O grau inicial será levado como consideração como baseline inicial\n",
    " \n",
    "\n",
    "all_text = []\n",
    "for i in range(len(dict_EQ)):\n",
    "    try:\n",
    "        for j in range(len(dict_EQ[i]['data'])):\n",
    "            text = dict_EQ[i]['data'][j]['text']\n",
    "            for tweet in [dict_EQ[i]['data'][j]['text']]:\n",
    "                analysis = tb(tweet)\n",
    "                polarity = analysis.sentiment.polarity\n",
    "            retweet = dict_EQ[i]['data'][j]['public_metrics']['retweet_count']\n",
    "            like = dict_EQ[i]['data'][j]['public_metrics']['like_count']\n",
    "            date = dict_EQ[i]['data'][j]['created_at'].split('T')[0]\n",
    "            for z in range(len(dict_EQ_GEO)):\n",
    "                if dict_EQ_GEO[z]['id'] == dict_EQ[i]['data'][j]['geo']['place_id']:\n",
    "                    lat = dict_EQ_GEO[z]['centroid'][1]\n",
    "                    long = dict_EQ_GEO[z]['centroid'][0]\n",
    "            all_text.append(dict(text = text,\n",
    "                                score = polarity,\n",
    "                                retweet = retweet,\n",
    "                                like = like,\n",
    "                                date = date,\n",
    "                                lat = lat,\n",
    "                                long = long\n",
    "                                )) \n",
    "    except:\n",
    "        continue  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "EQ_df = pd.DataFrame(all_text)\n",
    "EQ_df.to_csv('EQ_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7758e92e9a61d7a3490898707f7eeb937c85e9d1e8d4e877cc6c187218f226d5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
